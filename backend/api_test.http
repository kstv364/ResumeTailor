### Health Check
GET http://localhost:8000/health

### Upload Resume
POST http://localhost:8000/upload/
Content-Type: application/json

{
"id": "b3e1c2d4-5678-4f9a-8a2b-123456789abc",
  "file_url": "https://raw.githubusercontent.com/kstv364/Resume/e22164375f41d4c313b5b65fd1a09c98f6ed426a/Kaustav-Resume.pdf"
}

### Tailor Resume
POST http://localhost:8000/tailor/
Content-Type: application/json

{
  "resume_id": "b3e1c2d4-5678-4f9a-8a2b-123456789abc",
  "job_description": "Job Profile At Schneider Electric, we are committed to solving real-world problems to create a sustainable, digitized, new electric future. Artificial Intelligence has the potential to transform industries and help unlock efficiency and sustainability.\nAs part of the AI Technology group (70 people), we are seeking an ML engineer who can contribute to the development of our AI platform, which is used by our internal stakeholders to design and deploy AI use cases for our external offers and internal functions. We look for someone who is passionate about solving complex business & technical problems by applying best in class engineering, quality, and security practices in the context of AI software developments & integration.\n\nOur AI platform is built on top of Azure & AWS cloud providers, and also leverages Databricks solution.\n\nIf you're excited by the opportunity to positively impact business processes through innovation and application of advanced technologies, you will feel at home.\n\nResponsibilities\n\n· Contribute to the industrialization of the ML & GenAI technical stacks of our AI Platform, by participating to their definition, architecture, development, test, documentation & maintenance phases\n· Ensure the development process of this stack follows the DevSecOps recommendations & best practices\n· Write ML pipelines to illustrate the AI Platform capabilities\n· Contribute to the CI/CD workflows developments to automate the integration and deployment of the various ML assets (code or models) into the different environments\n· Contribute to the definition of the LLMOps / MLOps operating model and make sure the AI Platform enforces this model\n· Collaborate with our internal stakeholders to co-design the new features of the AI Platform\n· Occasionally be embarked into one of our stakeholders teams to help them using the AI platform, write ML pipelines, and, in return, collect platform evolution needs\n· Occasionally contribute to the collective effort of run & support for the AI Platform\n\nQualifications - External\n\nRequirements and Skills\n\n· 5+ years of experience in ML Engineering\n· Strong knowledge on Machine Learning (including ML model management context) and GenAI technologies (including RAG)\n· Previous hands-on experience on MLOps or LLMOps disciplines is mandatory\n· Good knowledge of DevOps processes at scale and experience of production systems\n· Rigorous mindset (but still open to changes), oriented towards customers, problems solving & results\n· Good team player\n· Autonomous\n· Ideally, some knowledge of Energy Management and Automation market\n· At ease in an international work environment & fluent in english\n· Familiar with agile methodologies: Scrum, SAFe\n· Technologies: Azure and/or AWS cloud technologies and their respective ML plateforms (AzureML, AWS SageMaker), Databricks, Github, Terraform, ML Tools such as MLFlow, GenAI & LLM tools"
}
